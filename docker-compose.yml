services:
  # DIGIPIN Backend API (Port 5002)
  digipin:
    build:
      context: ./digipin
      dockerfile: Dockerfile
    container_name: digipin-api
    ports:
      - "5002:5002"  
    environment:
      - NODE_ENV=production
      - PORT=5002
    restart: unless-stopped
    networks:
      - delivery-network
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:5002/health"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s

  # ML Microservice (Port 8000)
  ml-service:
    build:
      context: ./ml
      dockerfile: Dockerfile
    container_name: ml-service
    ports:
      - "8000:8000"
    environment:
      - CSV_PATH=/data/all_india_pincode_directory_2025.csv
      - ML_PORT=8000
      - ML_HOST=0.0.0.0
      - DIGIPIN_API_URL=http://digipin:5002
      - MODEL_NAME=sentence-transformers/all-MiniLM-L6-v2
    volumes:
      - ./post:/data:ro  # Mount data directory as read-only
      - ml-models-cache:/root/.cache  # Cache for ML models
      - ml-faiss-cache:/app/cache  # Cache for FAISS index and metadata
    restart: unless-stopped
    networks:
      - delivery-network
    depends_on:
      digipin:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "python -c 'import requests; requests.get(\"http://localhost:8000/health\")' || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 90s  # ML models need time to load

  # Backend API (Port 3001)
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: backend-api
    ports:
      - "3001:3001"
    environment:
      - NODE_ENV=production
      - PORT=3001
      - HOST=0.0.0.0
      - DIGIPIN_API_URL=http://digipin:5002
      - ML_API_URL=http://ml-service:8000
      - CSV_PATH=/data/all_india_pincode_directory_2025.csv
      - CORS_ORIGIN=http://localhost:5173
      - RATE_LIMIT_WINDOW_MS=900000
      - RATE_LIMIT_MAX_REQUESTS=100
      - MAX_FILE_SIZE=10485760
      - BATCH_CHUNK_SIZE=10
    volumes:
      - ./post:/data:ro
      - backend-uploads:/app/uploads
      - backend-logs:/app/logs
    restart: unless-stopped
    networks:
      - delivery-network
    depends_on:
      digipin:
        condition: service_healthy
      ml-service:
        condition: service_started  # Changed from service_healthy to service_started
    healthcheck:
      test: ["CMD-SHELL", "wget --no-verbose --tries=1 --spider http://localhost:3001/api/health/live || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 20s

  # Frontend (Port 5173)
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
      args:
        # Build-time variables only - NO SECRETS HERE
        - VITE_API_URL=http://localhost:3001
        - VITE_DIGIPIN_API_URL=http://localhost:5002
        - VITE_ML_API_URL=http://localhost:8000
        - VITE_GOOGLE_CLIENT_ID=372975400843-ffr7c5j59nmga7tk2nbog6o5mjpgq11s.apps.googleusercontent.com
    container_name: frontend-app
    ports:
      - "5173:80"  # Map container port 80 to host 5173
    environment:
      - NODE_ENV=production
    restart: unless-stopped
    networks:
      - delivery-network
    depends_on:
      backend:
        condition: service_started  # Changed to service_started to not wait for health
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:80"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

networks:
  delivery-network:
    driver: bridge
    name: delivery-network

volumes:
  ml-models-cache:
    name: ml-models-cache
    driver: local
  ml-faiss-cache:
    name: ml-faiss-cache
    driver: local
  backend-uploads:
    name: backend-uploads
    driver: local
  backend-logs:
    name: backend-logs
    driver: local
